{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3445781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.split import eval_splits, get_all_combs, get_valid_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7000ace",
   "metadata": {},
   "source": [
    "1. Find combination of comments that reach 85% and 15% of the train data $\\approx$ 60% and 10% of the full dataset.\n",
    "2. Find which combination has the most similar topic distribution to the original train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef9bc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = pd.read_csv(\"../data/detests/train_with_disagreement_context_soft.csv\").fillna(\"\")\n",
    "# train_val_no_fill = pd.read_csv(\"../data/detests/train_with_disagreement_context_no_fill_soft.csv\").fillna(\"\")\n",
    "labels = [\n",
    "    \"xenophobia\",\n",
    "    \"suffering\",\n",
    "    \"economic\",\n",
    "    \"migration\",\n",
    "    \"culture\",\n",
    "    \"benefits\",\n",
    "    \"health\",\n",
    "    \"security\",\n",
    "    \"dehumanisation\",\n",
    "    \"others\",\n",
    "]\n",
    "labels_groups = labels + [\"implicit\"]\n",
    "y_columns = [\"stereo\"] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96282b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The category distribution of the data in general is: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>suffering</th>\n",
       "      <th>economic</th>\n",
       "      <th>migration</th>\n",
       "      <th>culture</th>\n",
       "      <th>benefits</th>\n",
       "      <th>health</th>\n",
       "      <th>security</th>\n",
       "      <th>dehumanisation</th>\n",
       "      <th>others</th>\n",
       "      <th>implicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3801</td>\n",
       "      <td>3754</td>\n",
       "      <td>3762</td>\n",
       "      <td>3496</td>\n",
       "      <td>3628</td>\n",
       "      <td>3611</td>\n",
       "      <td>3800</td>\n",
       "      <td>3562</td>\n",
       "      <td>3752</td>\n",
       "      <td>3750</td>\n",
       "      <td>3162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>321</td>\n",
       "      <td>189</td>\n",
       "      <td>206</td>\n",
       "      <td>17</td>\n",
       "      <td>255</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xenophobia  suffering  economic  migration  culture  benefits  health  \\\n",
       "0        3801       3754      3762       3496     3628      3611    3800   \n",
       "1          16         63        55        321      189       206      17   \n",
       "\n",
       "   security  dehumanisation  others  implicit  \n",
       "0      3562            3752    3750      3162  \n",
       "1       255              65      67       655  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"The category distribution of the data in general is: \\n\")\n",
    "gen_dist = train_val[labels_groups].apply(pd.Series.value_counts)\n",
    "gen_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ec7dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xenophobia</th>\n",
       "      <th>suffering</th>\n",
       "      <th>economic</th>\n",
       "      <th>migration</th>\n",
       "      <th>culture</th>\n",
       "      <th>benefits</th>\n",
       "      <th>health</th>\n",
       "      <th>security</th>\n",
       "      <th>dehumanisation</th>\n",
       "      <th>others</th>\n",
       "      <th>implicit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.58</td>\n",
       "      <td>98.35</td>\n",
       "      <td>98.56</td>\n",
       "      <td>91.59</td>\n",
       "      <td>95.05</td>\n",
       "      <td>94.6</td>\n",
       "      <td>99.55</td>\n",
       "      <td>93.32</td>\n",
       "      <td>98.3</td>\n",
       "      <td>98.24</td>\n",
       "      <td>82.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.42</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.44</td>\n",
       "      <td>8.41</td>\n",
       "      <td>4.95</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.76</td>\n",
       "      <td>17.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   xenophobia  suffering  economic  migration  culture  benefits  health  \\\n",
       "0       99.58      98.35     98.56      91.59    95.05      94.6   99.55   \n",
       "1        0.42       1.65      1.44       8.41     4.95       5.4    0.45   \n",
       "\n",
       "   security  dehumanisation  others  implicit  \n",
       "0     93.32            98.3   98.24     82.84  \n",
       "1      6.68             1.7    1.76     17.16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_dist *= 100 / len(train_val)\n",
    "gen_dist.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a8f33",
   "metadata": {},
   "source": [
    "## Split with comment_id and threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547a993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of distinct comments is 1721\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of distinct comments is {train_val[\"comment_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = train_val[[\"comment_id\", \"reply_to\"]].groupby(\"comment_id\").tail(1)\n",
    "G = nx.Graph()\n",
    "G.add_edges_from(comments.to_numpy().tolist())\n",
    "comps = list(nx.connected_components(G))\n",
    "print(f\"The number of distinct threads is {len(comps)}\")\n",
    "comps[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8c4a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = np.array([len(c) for c in comps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(le == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fffa1d4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def number_comp(comment_id):\n",
    "    i = 0\n",
    "    while comment_id not in comps[i]:\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "train_val[\"thread\"] = train_val[\"comment_id\"].apply(number_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b797ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "1. Find combination of news that reach 15% of the data\n",
    "2. Find which of these combinations has the most similar topic distribution\n",
    "\n",
    "+ Problem: too many combinations\n",
    "+ Approach: Batch of threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_files_sz(df, column, batch_size=10):\n",
    "    file_sz = df.groupby(column).size().sample(frac=1, random_state=42)\n",
    "    n_batches = (len(file_sz) - 1) // batch_size + 1\n",
    "    return np.array_split(file_sz, n_batches)\n",
    "\n",
    "\n",
    "batches = batch_files_sz(train_val, \"thread\", 35)\n",
    "file_sz = pd.Series([batch.sum() for batch in batches])\n",
    "keys = [batch.keys().tolist() for batch in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9786935",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_splits = get_all_combs(file_sz, test_ratio=0.15, eps=0.01)\n",
    "valid_splits2 = [set(itertools.chain(*[keys[batch] for batch in split[0]])) for split in valid_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eval_splits(train_val, valid_splits2, \"thread\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb0af42",
   "metadata": {},
   "source": [
    "# Split with news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e784bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The number of distinct news is {train_val[\"file_id\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f794e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sz = train_val.groupby(\"file_id\").size().sort_values()\n",
    "file_sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c71fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_splits = get_all_combs(file_sz, test_ratio=0.15, eps=0.1)\n",
    "valid_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6aac60",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_splits2 = [split[0] for split in valid_splits]\n",
    "res = eval_splits(train_val, valid_splits2, \"file_id\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751798d",
   "metadata": {},
   "source": [
    "# Check results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3786b2",
   "metadata": {},
   "source": [
    "Sort results by MSE and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80610fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values(by=\"MSE\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c22cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sort_values(by=\"MAPE\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf1cc9",
   "metadata": {},
   "source": [
    "We keep the one with lower MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc475b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = \"file_id\"\n",
    "# field = \"thread\"\n",
    "val_split = valid_splits2[0]\n",
    "print(val_split)\n",
    "val = train_val[train_val[field].isin(val_split)]\n",
    "train = train_val[~train_val[field].isin(val_split)]\n",
    "\n",
    "# val_no_fill = train_val_no_fill[train_val[field].isin(val_split)]\n",
    "# train_no_fill = train_val_no_fill[~train_val[field].isin(val_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/detests/train_split_context_soft.csv\", index=False)\n",
    "val.to_csv(\"../data/detests/val_split_context_soft.csv\", index=False)\n",
    "\n",
    "# train_no_fill.to_csv(\"../data/detests/train_split_context_no_fill_soft.csv\", index=False)\n",
    "# val_no_fill.to_csv(\"../data/detests/val_split_context_no_fill_soft.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of train_val (original TRAIN dataset)\n",
    "perc_train_val = np.array([len(train), len(val)])\n",
    "perc_train_val = perc_train_val / len(train_val) * 100\n",
    "perc_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of whole dataset\n",
    "perc_train_val * 0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f648f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[labels_groups].apply(pd.Series.value_counts) / len(train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cb98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[labels_groups].apply(pd.Series.value_counts) / len(val) * 100"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
